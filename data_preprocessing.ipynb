{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPc1KTIYHqYQvXQFSAei0hB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimna21/ML_Final_Project/blob/main/data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5Iyx21zQi5k",
        "outputId": "ea95d65b-5d48-4486-8309-7d57f4bfc10f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install darts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTpRSO_9ibjv",
        "outputId": "6d563a80-d204-47c8-8a5f-6b9b67d200e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed adagio-0.2.6 appdirs-1.4.4 coreforecast-0.0.16 darts-0.36.0 fs-2.4.16 fugue-0.9.1 lightning-utilities-0.14.3 nfoursid-1.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyod-2.0.5 pytorch-lightning-2.5.2 statsforecast-2.0.2 tensorboardX-2.6.4 torchmetrics-1.7.3 triad-0.9.8 utilsforecast-0.2.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your data\n",
        "features = pd.read_csv('/content/drive/MyDrive/ML_Final_Project/features.csv')\n",
        "stores = pd.read_csv('/content/drive/MyDrive/ML_Final_Project/stores.csv')\n",
        "train = pd.read_csv('/content/drive/MyDrive/ML_Final_Project/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/ML_Final_Project/test.csv')"
      ],
      "metadata": {
        "id": "O7kgho2aU5nX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9w8wrTleQZwe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class BaseMerger(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, features, stores):\n",
        "        self.feature_store = features.merge(stores, how='inner', on='Store')\n",
        "        self.feature_store['Date'] = pd.to_datetime(self.feature_store['Date'])\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        X['Date'] = pd.to_datetime(X['Date'])\n",
        "        merged = X.merge(self.feature_store, how='inner', on=['Store', 'Date', 'IsHoliday'])\n",
        "        merged = merged.sort_values(by=['Store', 'Dept', 'Date']).reset_index(drop=True)\n",
        "        return merged"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import pandas as pd\n",
        "\n",
        "class FeatureAdder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.superbowl = pd.to_datetime(['2010-02-12', '2011-02-11', '2012-02-10', '2013-02-08'])\n",
        "        self.labor_day = pd.to_datetime(['2010-09-10', '2011-09-09', '2012-09-07', '2013-09-06'])\n",
        "        self.thanksgiving = pd.to_datetime(['2010-11-26', '2011-11-25', '2012-11-23', '2013-11-29'])\n",
        "        self.christmas = pd.to_datetime(['2010-12-31', '2011-12-30', '2012-12-28', '2013-12-27'])\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "\n",
        "        # Convert temperature to Celsius\n",
        "        if 'Temperature' in X.columns:\n",
        "            X['Temperature'] = (X['Temperature'] - 32) * (5.0 / 9.0)\n",
        "\n",
        "        # Basic date parts\n",
        "        X['Day'] = X['Date'].dt.day\n",
        "        X['Month'] = X['Date'].dt.month\n",
        "        X['Year'] = X['Date'].dt.year\n",
        "\n",
        "        # Extract ISO week and year for holiday matching\n",
        "        X['Week'] = X['Date'].dt.isocalendar().week\n",
        "        X['YearNum'] = X['Date'].dt.year\n",
        "\n",
        "        # Helper to flag if a date is in same ISO week/year as a known holiday\n",
        "        def is_holiday_week(date_series, holidays):\n",
        "            holiday_weeks = set((d.isocalendar().week, d.year) for d in holidays)\n",
        "            return date_series.apply(lambda d: (d.isocalendar().week, d.year) in holiday_weeks if pd.notnull(d) else False).astype(int)\n",
        "\n",
        "        X['SuperbowlWeek'] = is_holiday_week(X['Date'], self.superbowl)\n",
        "        X['LaborDayWeek'] = is_holiday_week(X['Date'], self.labor_day)\n",
        "        X['ThanksgivingWeek'] = is_holiday_week(X['Date'], self.thanksgiving)\n",
        "        X['ChristmasWeek'] = is_holiday_week(X['Date'], self.christmas)\n",
        "\n",
        "        # Calculate days to Thanksgiving and Christmas (using Nov 24 and Dec 24 as anchor dates)\n",
        "        thanksgiving_dates = pd.to_datetime(X['Year'].astype(str) + \"-11-24\")\n",
        "        christmas_dates = pd.to_datetime(X['Year'].astype(str) + \"-12-24\")\n",
        "\n",
        "        X['Days_to_Thanksgiving'] = (thanksgiving_dates - X['Date']).dt.days\n",
        "        X['Days_to_Christmas'] = (christmas_dates - X['Date']).dt.days\n",
        "\n",
        "        # Clean up helper cols\n",
        "        X = X.drop(columns=['Week', 'YearNum'])\n",
        "\n",
        "        return X\n"
      ],
      "metadata": {
        "id": "XWS8g3yNSoVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import pandas as pd\n",
        "\n",
        "class MissingValueFiller(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.markdown_cols = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\n",
        "        self.mean_cols = ['CPI', 'Unemployment']\n",
        "        self.mean_values = {}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        for col in self.mean_cols:\n",
        "            if col in X.columns:\n",
        "                self.mean_values[col] = X[col].mean()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "\n",
        "        # Fill markdowns with 0\n",
        "        for col in self.markdown_cols:\n",
        "            if col in X.columns:\n",
        "                X[col] = X[col].fillna(0.0)\n",
        "\n",
        "        # Fill CPI and Unemployment with learned mean\n",
        "        for col in self.mean_cols:\n",
        "            if col in X.columns and col in self.mean_values:\n",
        "                X[col] = X[col].fillna(self.mean_values[col])\n",
        "\n",
        "        return X\n"
      ],
      "metadata": {
        "id": "E3qFtNVaU7l9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.type_mapping = {'A': 3, 'B': 2, 'C': 1}\n",
        "        self.holiday_mapping = {False: 0, True: 1}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "\n",
        "        if 'Type' in X.columns:\n",
        "            X['Type'] = X['Type'].map(self.type_mapping)\n",
        "\n",
        "        if 'IsHoliday' in X.columns:\n",
        "            X['IsHoliday'] = X['IsHoliday'].map(self.holiday_mapping)\n",
        "\n",
        "        return X\n"
      ],
      "metadata": {
        "id": "0GkcpW1Ohhyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('merge', BaseMerger(features, stores)),\n",
        "    ('feature_add', FeatureAdder()),\n",
        "    ('fillna', MissingValueFiller()),\n",
        "    ('label_encode', CategoricalEncoder())\n",
        "])"
      ],
      "metadata": {
        "id": "frpkg1zLVD6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pipeline.fit_transform(train)"
      ],
      "metadata": {
        "id": "Bw0EWEuMWkJZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}